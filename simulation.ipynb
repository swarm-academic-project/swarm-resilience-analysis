{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b103bea-b839-4b66-a3c5-f4f9f18485cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119710f-6c78-42bd-ad5c-b559bf5d42f6",
   "metadata": {},
   "source": [
    "### extraction Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807292cf-f13f-4798-bd5c-4c63e687f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Traces.csv\", header=None)  \n",
    "\n",
    "# Créer les noms de colonnes pour le temps\n",
    "time_cols = [str(i+1) for i in range(10000)]\n",
    "df.columns = time_cols\n",
    "\n",
    "#générer les noms des lignes (cordonnées des satellites):\n",
    "coord_names = []\n",
    "for i in range(1, 101):  # 100 satellites\n",
    "    coord_names.append(f\"satx{i}\")\n",
    "    coord_names.append(f\"saty{i}\")\n",
    "    coord_names.append(f\"satz{i}\")\n",
    "df[\"coords\"] = coord_names\n",
    "df = df.set_index(\"coords\")\n",
    "\n",
    "dft = df.transpose()  # maintenant chaque ligne = un instant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82e932-d93a-4317-89b2-27b394dbbf62",
   "metadata": {},
   "source": [
    "### convert to swarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2e6b6-4b1c-446c-a686-507d9a74e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_range = 60\n",
    "portee1 =20\n",
    "portee2=40\n",
    "portee3= 60\n",
    "nanosat_count = 100\n",
    "max_temps = 100  # pour test rapide\n",
    "\n",
    "for t in range(len(dft)):\n",
    "    coords = dft.iloc[t]\n",
    "    nodes = []\n",
    "    \n",
    "    # Créer les objets Node\n",
    "    for i in range(1, nanosat_count + 1):\n",
    "        x = coords[f'satx{i}']\n",
    "        y = coords[f'saty{i}']\n",
    "        z = coords[f'satz{i}']\n",
    "        nodes.append(Node(id=i, x=x, y=y, z=z))\n",
    "\n",
    "    # Créer un graphe pondéré\n",
    "    G = nx.Graph()\n",
    "    for node in nodes:\n",
    "        G.add_node(node.id)\n",
    "\n",
    "    # Ajouter les arêtes avec poids selon la distance\n",
    "    for i in range(len(nodes)):\n",
    "        for j in range(i + 1, len(nodes)):\n",
    "            dist = nodes[i].compute_dist(nodes[j])\n",
    "            if dist <= portee1:\n",
    "                weight = 1\n",
    "            elif dist <= portee2:\n",
    "                weight = 2\n",
    "            elif dist <= portee3:\n",
    "                weight = 3\n",
    "            else:\n",
    "                continue  \n",
    "            G.add_edge(nodes[i].id, nodes[j].id, weight=weight)\n",
    "        # ----- Étape 1 : Métriques de base (graphe non divisé) -----\n",
    "    metriques_avant = {\n",
    "        \"time\": t,\n",
    "        \"algo\": \"none\",\n",
    "        \"attack\": \"none\",\n",
    "        \"efficacite\": network_efficiency(G),\n",
    "        \"cout\": routing_cost(G),\n",
    "        \"robustesse\": flow_robustness(G),\n",
    "        \"redondance\": path_redundancy(G),\n",
    "        \"disparite\": path_disparity(G),\n",
    "        \"criticite\": critical_nodes(G)\n",
    "    }\n",
    "    resultats.append(metriques_avant)\n",
    "\n",
    "    # ----- Étape 2 : Pour chaque algorithme de division -----\n",
    "        groupes = swarm.MDRW(n=5)\n",
    "\n",
    "        # Construire group_dict\n",
    "        group_dict = {}\n",
    "        for group_id, sub_swarm in groupes.items():\n",
    "            for n in sub_swarm.nodes:\n",
    "                group_dict[n.id] = group_id\n",
    "\n",
    "        # ----- Métriques post-division -----\n",
    "        metriques_div = {\n",
    "            \"time\": t,\n",
    "            \"algo\": algo,\n",
    "            \"attack\": \"none\",\n",
    "            \"efficacite\": network_efficiency(G, divided=True, group_dict=group_dict),\n",
    "            \"cout\": routing_cost(G, divided=True, group_dict=group_dict),\n",
    "            \"robustesse\": flow_robustness(G, divided=True, group_dict=group_dict),\n",
    "            \"redondance\": path_redundancy(G, divided=True, group_dict=group_dict),\n",
    "            \"disparite\": path_disparity(G, divided=True, group_dict=group_dict),\n",
    "            \"criticite\": critical_nodes(G, divided=True, group_dict=group_dict)\n",
    "        }\n",
    "        resultats.append(metriques_div)\n",
    "\n",
    "        # ----- Étape 3 : Appliquer les attaques -----\n",
    "          attack_type= \"random\"\n",
    "           nb_noeuds_supprimes = 40 \n",
    "            G_copy = G.copy()\n",
    "            BC = node_criticality(G_copy if attack_type == \"cible\" else None,\n",
    "                                  divided=True, group_dict=group_dict)\n",
    "            if attack_type == \"random\":\n",
    "                nodes_to_remove = random.sample(list(G_copy.nodes), nb_noeuds_supprimes)\n",
    "            else:  # \"cible\"\n",
    "                nodes_to_remove = sorted(BC, key=BC.get, reverse=True)[:nb_noeuds_supprimes]\n",
    "\n",
    "            G_copy.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "            # ----- Métriques post-attaque -----\n",
    "            metriques_attaque = {\n",
    "                \"time\": t,\n",
    "                \"algo\": algo,\n",
    "                \"attack\": attack_type,\n",
    "                \"efficacite\": network_efficiency(G_copy, divided=True, group_dict=group_dict),\n",
    "                \"cout\": routing_cost(G_copy, divided=True, group_dict=group_dict),\n",
    "                \"robustesse\": flow_robustness(G_copy, divided=True, group_dict=group_dict),\n",
    "                \"redondance\": path_redundancy(G_copy, divided=True, group_dict=group_dict),\n",
    "                \"disparite\": path_disparity(G_copy, divided=True, group_dict=group_dict),\n",
    "                \"criticite\": critical_nodes(G_copy, divided=True, group_dict=group_dict)\n",
    "            }\n",
    "            resultats.append(metriques_attaque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cc8b4-5c53-4c55-b7ef-e4892bb3c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Sauvegarde en CSV ==========\n",
    "df_res = pd.DataFrame(resultats)\n",
    "df_res.to_csv(\"resultats_swarm_simulation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
